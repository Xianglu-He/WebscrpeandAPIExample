{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Web Scrape Example --- Ebay\n",
    "Xianglu He"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Packages\n",
    "import requests\n",
    "import urllib\n",
    "import json\n",
    "import mysql.connector\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part I\n",
    "\n",
    "#Type in the URL Batch Request\n",
    "url = 'http://numbersapi.com/0..99'\n",
    "#Get the trivia results through website batch API\n",
    "request = requests.get(url)\n",
    "#Save the result in json format named as data\n",
    "data = request.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a data_list variable\n",
    "data_list = []\n",
    "#Change the json format into list format \n",
    "for key in data:\n",
    "    data_list.append(data[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the final result as a list variable\n",
    "final_result = []\n",
    "#Append the number with 3 digits format with the result requested from the API\n",
    "for i in range(len(data_list)) :\n",
    "  final_result.append(\"{0:03}\".format(i) + ' - ' + data_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000 - 0 is the atomic number of the theoretical element tetraneutron.\n",
      "001 - 1 is the number of moons orbiting Earth.\n",
      "002 - 2 is the number of polynucleotide strands in a DNA double helix.\n",
      "003 - 3 is cans of Spam consumed every second in the United States.\n",
      "004 - 4 is the number of completed, numbered symphonies by Johannes Brahms.\n",
      "005 - 5 is the number of Justices on the Supreme Court of the United States necessary to render a majority decision.\n",
      "006 - 6 is the highest number on one end of a standard domino.\n",
      "007 - 7 is the number of types of viruses according to the Baltimore classification.\n",
      "008 - 8 is the number of principles of Yong in Chinese calligraphy.\n",
      "009 - 9 is the number of circles of Hell in Dante's Divine Comedy.\n",
      "010 - 10 is the average thickness of the Arctic ice sheet in feet.\n",
      "011 - 11 is the approximate periodicity of a sunspot cycle in years.\n",
      "012 - 12 is the number of ounces in a troy pound (used for precious metals).\n",
      "013 - 13 is the speed of rush hour traffic on average in kilometres per hour in London.\n",
      "014 - 14 is the maximum number of electrons that can fit in an f sublevel.\n",
      "015 - 15 is the number of balls in the eight ball variant of billiards.\n",
      "016 - 16 is the minimum age that one can drop out of school in most states of the US (however, restrictions apply and vary depending on state).\n",
      "017 - 17 is the maximum number of strokes of a Chinese radical.\n",
      "018 - 18 is the number of colors the labels for Crayola crayons come in.\n",
      "019 - 19 is the final year a person is a teenager.\n",
      "020 - 20 is the number of questions in the popular party game Twenty Questions.\n",
      "021 - 21 is the number of trump cards of the tarot deck if one does not consider The Fool to be a proper trump card.\n",
      "022 - 22 is the number of yards in a chain.\n",
      "023 - 23 is the number of crosses on Calvary in the Monty Python film Life Of Brian.\n",
      "024 - 24 is the number of cycles in the Chinese solar year.\n",
      "025 - 25 is the percentage of all scald burns to children from hot tap water.\n",
      "026 - 26 is the number of episodes in a television program each year (usually).\n",
      "027 - 27 is the current number of Amendments to the United States Constitution (2012 February).\n",
      "028 - 28 is the number of grams in an ounce (approximately), and used as such in the illegal drug trade.\n",
      "029 - 29 is the number of attributes existing according to The Strokes in You Only Live Once.\n",
      "030 - 30 is the minimum age for United States senators.\n",
      "031 - 31 is the number of days in the months January, March, May, July, August, October and December.\n",
      "032 - 32 is the number of teeth of a full set of teeth in an adult human, including wisdom teeth.\n",
      "033 - 33 is the number of workers trapped, and also the number of survivors of the 2010 Copiap√≥ mining accident.\n",
      "034 - 34 is the lucky number of Victor Pelevin's protagonist Stepan Mikhailov in the novel Numbers.\n",
      "035 - 35 is the minimum age of candidates for election to the United States Presidency.\n",
      "036 - 36 is the perfect score on the ACT.\n",
      "037 - 37 is the number of plays William Shakespeare is thought to have written (counting Henry IV as three parts).\n",
      "038 - 38 is the number of games that each team in the current English Premiership, the top division in English Association Football, plays in a season.\n",
      "039 - 39 is the traditional number of times citizens of Ancient Rome hit their slaves when beating them, referred to as \"Forty save one\".\n",
      "040 - 40 is the number of attempts needed before the creation of the \"water displacing\" substance in the spray WD-40.\n",
      "041 - 41 is the number of times Paul McCartney sings the phrase \"Let It Be\" in the Beatles' hit Let It Be.\n",
      "042 - 42 is the angle in degrees for which a rainbow appears or the critical angle.\n",
      "043 - 43 is the maximum number of cars participating in a NASCAR race in the Cup Series or Nationwide Series.\n",
      "044 - 44 is the percentage of kids who watch television before they go to sleep in the US.\n",
      "045 - 45 is the sapphire wedding anniversary in years of marriage.\n",
      "046 - 46 is the number of slices of pizza an average American kid eats in a year.\n",
      "047 - 47 is the number of phonemes in English phonology in Received Pronunciation.\n",
      "048 - 48 is the number of Ptolemaic constellations.\n",
      "049 - 49 is the number of days and night Siddhartha Gautama spent meditating as a holy man.\n",
      "050 - 50 is the number of states in the United States of America.\n",
      "051 - 51 is the atomic number of antimony.\n",
      "052 - 52 is the number of white keys (notes in the C major scale).\n",
      "053 - 53 is the number of bytes in an Asynchronous Transfer Mode packet.\n",
      "054 - 54 is the number of milligrams of caffeine Mountain Dew has.\n",
      "055 - 55 is the common speed limit for rural secondary roads and many urban freeways in many states of the United States.\n",
      "056 - 56 is the number of men who signed the United States Declaration of Independence in 1776.\n",
      "057 - 57 is the number of cm that the smallest man measured, Gul Mohammed (1957-1997) of India.\n",
      "058 - 58 is the minimum wind speed (mph) needed to issue a Severe Thunderstorm Warning.\n",
      "059 - 59 is the number of days, approximately in two lunar months.\n",
      "060 - 60 is the number of minutes in an hour.\n",
      "061 - 61 is the number of points required to win a \"standard\" game of Cribbage.\n",
      "062 - 62 is the number which Sigmund Freud has an irrational fear of.\n",
      "063 - 63 is the atomic number of europium.\n",
      "064 - 64 is number of golden disks in the myth of the Tower of Hanoi.\n",
      "065 - 65 is the minimum grade required to pass an exam, or class, in many areas.\n",
      "066 - 66 is the number of hot dogs eaten by World record holder Joey Chestnut in 15 minutes.\n",
      "067 - 67 is the number of throws in Judo.\n",
      "068 - 68 is the ideal temperature (F) for developing black-and-white film.\n",
      "069 - 69 is the number Bill and Ted were thinking of when talking to their future selves.\n",
      "070 - 70 is the distance (meter) from archer to targets in Olympic Archery.\n",
      "071 - 71 is the atomic number of lutetium.\n",
      "072 - 72 is the number of episodes in the original airing of Futurama.\n",
      "073 - 73 is the percentage of girls in Bangladesh that are married by age 18.\n",
      "074 - 74 is the number of stars obtained by SpongeBob SquarePants in his driving school.\n",
      "075 - 75 is the age limit for Canadian senators.\n",
      "076 - 76 is the atomic number of osmium.\n",
      "077 - 77 is the atomic number of iridium.\n",
      "078 - 78 is the total number of gifts in the song The Twelve Days of Christmas.\n",
      "079 - 79 is the record for cumulative weeks at #1 on the Billboard charts, held by Elvis Presley.\n",
      "080 - 80 is a common limit for the characters per line in computing (derived from the number of columns in IBM cards).\n",
      "081 - 81 is the number of stanzas or chapters in the Tao te Ching (in the most common arrangements).\n",
      "082 - 82 is the number of games in an NBA or NHL regular season.\n",
      "083 - 83 is the atomic number of bismuth.\n",
      "084 - 84 is the atomic number of polonium.\n",
      "085 - 85 is the IQ and nickname of Aaron in Alien 3.\n",
      "086 - 86 is the device number for a lockout relay function in electrical circuit protection schemes.\n",
      "087 - 87 is the number of tools in the Wenger Swiss Army Knife version XXL, listed in the Guinness Book of World Records as the world's most multi-functional penknife.\n",
      "088 - 88 is a standard length of playing cards in mm.\n",
      "089 - 89 is the number of units of each colour in the board game Blokus.\n",
      "090 - 90 is the number of minutes in a football (soccer) match.\n",
      "091 - 91 is the code for international direct dial phone calls to India.\n",
      "092 - 92 is the number of stories in the Xujiahui Tower proposed to be built in Shanghai, China.\n",
      "093 - 93 is that approximate distance in millions of miles the Sun is away from the Earth.\n",
      "094 - 94 is the atomic number of plutonium.\n",
      "095 - 95 is the percentage confidence interval that is considered satisfactory for most purposes in statistics.\n",
      "096 - 96 is the rating of Skyrim on metacritic.com.\n",
      "097 - 97 is the atomic number of berkelium.\n",
      "098 - 98 is the highest jersey number allowed in the National Hockey League (as 99 was retired by the entire league to honor Wayne Gretzky).\n",
      "099 - 99 is the highest jersey number allowed in most major league sports.\n"
     ]
    }
   ],
   "source": [
    "#Print the result line by line\n",
    "for i in range(len(final_result)):\n",
    "    print(final_result[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part Two"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part A\n",
    "\n",
    "To include Buy-it-now items, we could add an extension condition filter to the current search engine. The condition would be 'LH_BIN'\n",
    "The GET request for buy-it-now items is https://www.ebay.com/sch/i.html?_nkw=samsung+tv&rt=nc&LH_BIN=\n",
    "\n",
    "To include 100 items per search result page, we could add an extension condition filter to the current search engine. The condition would be '_ipg=100'\n",
    "The GET request for 100 items per search result is https://www.ebay.com/sch/i.html?_nkw=samsung+tv&_ipg=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part B\n",
    "# pretend I am a browser\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.88 Safari/537.36'}\n",
    "url = 'https://www.ebay.com/sch/i.html?_nkw=playstation+4+slim&_ipg=100&_pgn='\n",
    "\n",
    "#Create empyty list to save the links\n",
    "url_spon = []\n",
    "url_no = []\n",
    "\n",
    "#Open the page from 1 to 10 on Ebay and save links into above two lists\n",
    "for pgn in range(1,11):\n",
    "    new_url = url + str(pgn)\n",
    "    # open a new session\n",
    "    session = requests.Session() \n",
    "    # log on to the session and get the content of said url \n",
    "    response = session.get(new_url,headers=headers) \n",
    "    test = response.text\n",
    "    soup = BeautifulSoup(test, 'html.parser') \n",
    "    page_ind = soup.select('li.s-item')\n",
    "    #Find the class that has unique pattern to identify sponsored links \n",
    "    for page_ind in page_ind:\n",
    "        a = page_ind.find('a')\n",
    "        if not a:\n",
    "            continue\n",
    "        page_ind = page_ind.find('span').get_text()\n",
    "        #The unique pattern\n",
    "        if bool(re.search(r'.*[S].*[P].*[O].*[N].*[S].*[O].*[R].*[E].*[D].*',page_ind)) == True:\n",
    "            #If the unique pattern is true, then save the link into Sponsored list\n",
    "            url_spon.append(re.sub(\"(.*)\\\\?.*\", r\"\\1\", a['href']))\n",
    "        #Else, save it into Non_Sponsored List\n",
    "        else:\n",
    "            url_no.append(re.sub(\"(.*)\\\\?.*\", r\"\\1\", a['href']))\n",
    "    #10 Second Gap between each request        \n",
    "    time.sleep(10)\n",
    "                \n",
    "\n",
    "#Save the sponsored links into a txt file called sponsored\n",
    "with open('sponsored.txt', 'w') as filehandle:\n",
    "    for listitem in url_spon:\n",
    "        filehandle.write('%s\\n' % listitem)\n",
    "        \n",
    "#Save the non_sponsored links into a txt file called non_sponsored\n",
    "with open('non-sponsored.txt', 'w') as filehandle:\n",
    "    for listitem in url_no:\n",
    "        filehandle.write('%s\\n' % listitem)       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part C\n",
    "\n",
    "#Create a folder function \n",
    "def createFolder(directory):\n",
    "    try:\n",
    "        #if the folder is not existed, then create the folder\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    #Error handling\n",
    "    except OSError:\n",
    "            print ('Error: Creating directory. ' +  directory)\n",
    "\n",
    "#Create sponsored and non-sponsored folders\n",
    "createFolder('./sponsored/')\n",
    "createFolder('./non-sponsored/')\n",
    "\n",
    "#Open the text file and strip the url into two lists\n",
    "sponsored_url = open('sponsored.txt','r')\n",
    "sponsored = []\n",
    "for x in sponsored_url:\n",
    "  sponsored.append(x.strip('\\n'))\n",
    "\n",
    "non_sponsored_url = open('non-sponsored.txt','r')\n",
    "non_sponsored = []\n",
    "for x in non_sponsored_url:\n",
    "  non_sponsored.append(x.strip('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the sponsored html file\n",
    "for pgn in range(len(sponsored)):\n",
    "    try:\n",
    "        #Default path\n",
    "        save_path = './sponsored/'\n",
    "        #Get the current new url\n",
    "        url = sponsored[pgn]\n",
    "        #Strip the item id from url\n",
    "        filename = re.findall(r'/([0-9]+)\\Z',url)\n",
    "        filename = filename[0]\n",
    "        #Save the name as default path + item id \n",
    "        completeName = os.path.join(save_path,filename+\".html\")\n",
    "        #Get the url request\n",
    "        response = requests.get(url, headers = headers)\n",
    "        #Write the request and save it into the default path\n",
    "        with open(completeName, 'w',encoding='utf8') as file:\n",
    "             file.write(response.text)\n",
    "    except ConnectionError as e: \n",
    "        print(e)\n",
    "    #2 second time gap\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the non-sponsored html file\n",
    "for pgn in range(len(non_sponsored)):\n",
    "    try:\n",
    "        #Default path\n",
    "        save_path = './non-sponsored/'\n",
    "        #Get the current new url\n",
    "        url = non_sponsored[pgn]\n",
    "        #Strip the item id from url\n",
    "        filename = re.findall(r'/([0-9]+)\\Z',url)\n",
    "        filename = filename[0]\n",
    "        #Save the name as default path + item id\n",
    "        completeName = os.path.join(save_path,filename+\".html\")\n",
    "        #Get the url request\n",
    "        response = requests.get(url, headers = headers)\n",
    "        #Write the request and save it into the default path\n",
    "        with open(completeName, 'w',encoding='utf8') as file:\n",
    "             file.write(response.text)\n",
    "    except ConnectionError as e: \n",
    "        print(e)\n",
    "    #2 second time gap\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sponsored Section\n",
    "#Create empty lists to store the value\n",
    "seller_name = []\n",
    "seller_score = []\n",
    "item_price = []\n",
    "item_sold = []\n",
    "best_offer = []\n",
    "title = []\n",
    "returns = []\n",
    "shipping = []\n",
    "condition = []\n",
    "Type = []\n",
    "#Default path and look for all of the html file\n",
    "list_of_files = glob.glob('./sponsored/*.html')\n",
    "for file_name in list_of_files:\n",
    "    #Open the html file\n",
    "    file = open(file_name, 'r',encoding='utf8') \n",
    "    text = file.read()\n",
    "    #Parse the information from the current url\n",
    "    soup = BeautifulSoup(text,'html.parser')\n",
    "    \n",
    "    #If soup has the seller_name information, append the value into seller_name list\n",
    "    #Seller_name is saved under span class called mbg-nw\n",
    "    if bool(soup.find('span',{'class':'mbg-nw'})) == True: \n",
    "        seller_name.append(soup.find('span',{'class':'mbg-nw'}).get_text())\n",
    "    #If soup does not have the information, save it as NULL\n",
    "    else: \n",
    "        seller_name.append('NULL')\n",
    "        \n",
    "    #If soup has the seller_score information, append the value into seller_score list\n",
    "    #Seller_score is saved under span class mbg-l\n",
    "    if bool(soup.find('span',{'class':'mbg-l'})) == True:\n",
    "        seller_score.append(re.findall('[0-9]+',soup.find('span',{'class':'mbg-l'}).get_text())[0])\n",
    "    #If soup does not have the information, save it as NULL\n",
    "    else: \n",
    "        seller_score.append('0')\n",
    "        \n",
    "    #If soup has the item_price information, append the value into item_price list\n",
    "    #Item_price is saved under span class notranslate \n",
    "    if bool(soup.find('span',{'class':'notranslate'})) == True:\n",
    "        #If the item_price has only one value\n",
    "        if len(re.findall('\\$([0-9]+\\.[0-9]+)',soup.find('span',{'class':'notranslate'}).get_text())) ==1:\n",
    "            #item_price.append(int(float(re.findall('\\$([0-9]+\\.[0-9]+)',soup.find('span',{'class':'notranslate'}).get_text())[0])*100))\n",
    "            #Save the value into item_price list\n",
    "            item_price.append(''.join(re.findall('[0-9]',soup.find('span',{'class':'notranslate'}).get_text())))\n",
    "        #else:item_price.append(re.findall('\\$([0-9]+\\.[0-9]+)',soup.find('span',{'class':'notranslate'}).get_text()))\n",
    "        #Save the value into item_price list\n",
    "        else: item_price.append(''.join(re.findall('[0-9]',soup.find('span',{'class':'notranslate'}).get_text())))\n",
    "    #If soup does not have the information, save it as 000\n",
    "    else: \n",
    "        item_price.append('000')\n",
    "        \n",
    "    #If soup has the item_sold information, append the value into item_sold list\n",
    "    #Item_sold is saved under a class vi-txt-underline\n",
    "    if bool(soup.find('a',{'class':'vi-txt-underline'})) == True:\n",
    "        #Save the value into item_sold list\n",
    "        item_sold.append(re.findall('[0-9]+',soup.find('a',{'class':'vi-txt-underline'}).get_text())[0])\n",
    "    #If soup does not have the information, save it as 0\n",
    "    else: \n",
    "        item_sold.append('0')\n",
    "        \n",
    "    #If soup has the best_offer information, append the value into best_offer list\n",
    "    #Best_offer is saved under div class vi-bbox-dspn u-flL lable boLable\n",
    "    if bool(soup.find('div',{'class':'vi-bbox-dspn u-flL lable boLable'})) == True:\n",
    "        #Save the value as True into best_offer list\n",
    "        best_offer.append('True')\n",
    "    \n",
    "    else: \n",
    "        best_offer.append('False')\n",
    "    \n",
    "    #If soup has the title information, append the value into title list\n",
    "    #Title is saved under h1 class it-ttl\n",
    "    if bool(soup.find('h1',{'class':'it-ttl'})) == True:\n",
    "        #Add the [0] position to remove the bracket []\n",
    "        title.append(re.findall(r'</span>(.+)</h1>',str(soup.find('h1',{'class':'it-ttl'})))[0])\n",
    "    #If soup does not have the information, save it as NULL\n",
    "    else: title.append('NULL')\n",
    "        \n",
    "    #If soup has the returns information, append the value into returns list\n",
    "    #Returns is saved under span id vi-ret-accrd-txt\n",
    "    if bool(soup.find('span',{'id':'vi-ret-accrd-txt'})) == True:\n",
    "        returns.append(soup.find('span',{'id':'vi-ret-accrd-txt'}).get_text())\n",
    "    #If soup does not have the information, save it as NULL\n",
    "    else: returns.append('NULL')\n",
    "        \n",
    "    #If soup does not find the pattern, save it as 000\n",
    "    #Shipping is saved under span id fshippingCost\n",
    "    if soup.find('span',attrs = {'id':'fshippingCost'}) == None:\n",
    "        shipping.append('000')\n",
    "    #If soup has the pattern\n",
    "    elif bool(soup.find('span',{'id':'fshippingCost'})) == True:\n",
    "        #Shipping price has more than one price, this is sometimes because of different currency\n",
    "        if len(re.findall('\\$([0-9]+\\.[0-9]+)',soup.find('span',attrs = {'id':'fshippingCost'}).get_text()))>1:\n",
    "            #Get the second position price, which is the US dollars and save it into shipping\n",
    "            shipping.append(float(re.findall('\\$([0-9]+\\.[0-9]+)',soup.find('span',attrs = {'id':'fshippingCost'}).get_text())[1])*100)\n",
    "        \n",
    "        else:\n",
    "            #The pattern has been found but return as empty, this is because it various by locations \n",
    "            if re.findall('\\$([0-9]+\\.[0-9]+)',soup.find('span',attrs = {'id':'fshippingCost'}).get_text()) == []:\n",
    "                #Save this condition as 000\n",
    "                shipping.append('000')\n",
    "            #Get the first position because it only has one shipping price and save it into shipping list\n",
    "            else: \n",
    "                shipping.append(float(re.findall('\\$([0-9]+\\.[0-9]+)',soup.find('span',attrs = {'id':'fshippingCost'}).get_text())[0])*100)\n",
    "    #Save the result of conditions into 000 as error handling\n",
    "    else: \n",
    "        shipping.append('000')\n",
    "    #Get the condition type and save it into condition list\n",
    "    #Condition is saved under div class u-flL condText\n",
    "    condition.append(soup.find('div',{'class':'u-flL condText'}).get_text())\n",
    "    #Save the type as sponsored\n",
    "    Type = 'sponsored'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concate all the columns and save it into a sponsored dataframe\n",
    "sponsored_df = pd.DataFrame({'seller_name': seller_name,\n",
    "                             'seller_score': seller_score,\n",
    "                             'item_price': item_price,\n",
    "                             'item_sold': item_sold,\n",
    "                             'best_offer': best_offer,\n",
    "                             'title': title,\n",
    "                             'returns': returns,\n",
    "                             'shipping': shipping,\n",
    "                             'condition': condition,\n",
    "                             'type': Type},\n",
    "                           columns=['seller_name','seller_score','item_price','item_sold','best_offer','title','returns','shipping','condition','type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non_Sponsored Section\n",
    "#Create empty lists to store the value\n",
    "seller_name = []\n",
    "seller_score = []\n",
    "item_price = []\n",
    "item_sold = []\n",
    "best_offer = []\n",
    "title = []\n",
    "returns = []\n",
    "shipping = []\n",
    "condition = []\n",
    "Type = []\n",
    "#Default path and look for all of the html file\n",
    "list_of_files = glob.glob('./non-sponsored/*.html')\n",
    "for file_name in list_of_files:\n",
    "    #Open the html file\n",
    "    file = open(file_name, 'r',encoding='utf8') \n",
    "    text = file.read()\n",
    "    #Parse the information from the current url\n",
    "    soup = BeautifulSoup(text,'html.parser')\n",
    "    \n",
    "    #If soup has the seller_name information, append the value into seller_name list\n",
    "    #Seller_name is saved under span class called mbg-nw\n",
    "    if bool(soup.find('span',{'class':'mbg-nw'})) == True: \n",
    "        seller_name.append(soup.find('span',{'class':'mbg-nw'}).get_text())\n",
    "    #If soup does not have the information, save it as NULL\n",
    "    else: \n",
    "        seller_name.append('NULL')\n",
    "        \n",
    "    #If soup has the seller_score information, append the value into seller_score list\n",
    "    #Seller_score is saved under span class mbg-l\n",
    "    if bool(soup.find('span',{'class':'mbg-l'})) == True:\n",
    "        seller_score.append(re.findall('[0-9]+',soup.find('span',{'class':'mbg-l'}).get_text())[0])\n",
    "    #If soup does not have the information, save it as 0\n",
    "    else: \n",
    "        seller_score.append('0')\n",
    "        \n",
    "    #If soup has the item_price information, append the value into item_price list\n",
    "    #Item_price is saved under a class notranslate\n",
    "    if bool(soup.find('span',{'class':'notranslate'})) == True:\n",
    "        #If the item_price has only one value\n",
    "        if len(re.findall('\\$([0-9]+\\.[0-9]+)',soup.find('span',{'class':'notranslate'}).get_text())) ==1:\n",
    "            #item_price.append(int(float(re.findall('\\$([0-9]+\\.[0-9]+)',soup.find('span',{'class':'notranslate'}).get_text())[0])*100))\n",
    "            #Save the value into item_price as joining the number one by one \n",
    "            item_price.append(''.join(re.findall('[0-9]',soup.find('span',{'class':'notranslate'}).get_text())))\n",
    "        #else:item_price.append(re.findall('\\$([0-9]+\\.[0-9]+)',soup.find('span',{'class':'notranslate'}).get_text()))\n",
    "        #If the item_price has more than one value case\n",
    "        else: item_price.append(''.join(re.findall('[0-9]',soup.find('span',{'class':'notranslate'}).get_text())))\n",
    "    #Save the value as 000 for all the left cases\n",
    "    else: \n",
    "        item_price.append('000')\n",
    "        \n",
    "    #If soup has the item_sold information, append the value into item_sold list\n",
    "    #Item_sold is saved under a class vi-txt-underline\n",
    "    if bool(soup.find('a',{'class':'vi-txt-underline'})) == True:\n",
    "        item_sold.append(re.findall('[0-9]+',soup.find('a',{'class':'vi-txt-underline'}).get_text())[0])\n",
    "    #If soup does not have the information, save it as 0\n",
    "    else: \n",
    "        item_sold.append('0')\n",
    "        \n",
    "    #If soup has the best_offer information, append the value into best_offer list\n",
    "    #Best_offer is saved under div class vi-bbox-dspn u-flL lable boLable\n",
    "    if bool(soup.find('div',{'class':'vi-bbox-dspn u-flL lable boLable'})) == True:\n",
    "        best_offer.append('True')\n",
    "    #If soup does not have the information, save it as FALSE\n",
    "    else: \n",
    "        best_offer.append('False')\n",
    "        \n",
    "    #If soup has the title information, append the value into title list\n",
    "    #Title is saved under h1 class it-ttl\n",
    "    if bool(soup.find('h1',{'class':'it-ttl'})) == True:\n",
    "        title.append(str(soup.find('h1',{'class':'it-ttl'})))\n",
    "    #If soup does not have the information, save it as NULL\n",
    "    else: title.append('NULL')\n",
    "        \n",
    "    #If soup has the returns information, append the value into returns list\n",
    "    #Returns is saved under span id vi-ret-accrd-txt    \n",
    "    if bool(soup.find('span',{'id':'vi-ret-accrd-txt'})) == True:\n",
    "        returns.append(soup.find('span',{'id':'vi-ret-accrd-txt'}).get_text())\n",
    "    #If soup does not have the information, save it as NULL\n",
    "    else: returns.append('NULL')\n",
    "        \n",
    "    #If soup does not find the pattern, save it as 000\n",
    "    #Shipping is saved under span id fshippingCost\n",
    "    if soup.find('span',attrs = {'id':'fshippingCost'}) == None:\n",
    "        shipping.append('000')\n",
    "    #If soup has the pattern\n",
    "    elif bool(soup.find('span',{'id':'fshippingCost'})) == True:\n",
    "        #Shipping price has more than one price, this is sometimes because of different currency\n",
    "        if len(re.findall('\\$([0-9]+\\.[0-9]+)',soup.find('span',attrs = {'id':'fshippingCost'}).get_text()))>1:\n",
    "            #Get the second position price, which is the US dollars and save it into shipping\n",
    "            shipping.append(float(re.findall('\\$([0-9]+\\.[0-9]+)',soup.find('span',attrs = {'id':'fshippingCost'}).get_text())[1])*100)\n",
    "        else:\n",
    "            #The pattern has been found but return as empty, this is because it various by locations \n",
    "            if re.findall('\\$([0-9]+\\.[0-9]+)',soup.find('span',attrs = {'id':'fshippingCost'}).get_text()) == []:\n",
    "                shipping.append('000')\n",
    "            #Get the first position because it only has one shipping price and save it into shipping list\n",
    "            else: \n",
    "                shipping.append(float(re.findall('\\$([0-9]+\\.[0-9]+)',soup.find('span',attrs = {'id':'fshippingCost'}).get_text())[0])*100)\n",
    "    #Save the result of conditions into 000 as error handling\n",
    "    else: \n",
    "        shipping.append('000')\n",
    "    #Get the condition type and save it into condition list\n",
    "    #Condition is saved under div class u-flL condText\n",
    "    if bool(soup.find('div',{'class':'u-flL condText'})) == True:\n",
    "        condition.append(soup.find('div',{'class':'u-flL condText'}).get_text())\n",
    "    else: condition.append('NULL')\n",
    "    #Save the type as sponsored\n",
    "    Type = 'non-sponsored'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove the bracket inside the non_sponsored title column\n",
    "for i in range(len(title)):\n",
    "    title[i] = re.findall(r'</span>(.+)</h1>',title[i])\n",
    "    title[i] = str(title[i]).replace('[','').replace(']','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concate all the columns and save it into a non_sponsored dataframe\n",
    "non_sponsored_df = pd.DataFrame({'seller_name': seller_name,\n",
    "                             'seller_score': seller_score,\n",
    "                             'item_price': item_price,\n",
    "                             'item_sold': item_sold,\n",
    "                             'best_offer': best_offer,\n",
    "                             'title': title,\n",
    "                             'returns': returns,\n",
    "                             'shipping': shipping,\n",
    "                             'condition': condition,\n",
    "                             'type': Type},\n",
    "                           columns=['seller_name','seller_score','item_price','item_sold','best_offer','title','returns','shipping','condition','type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seller_name</th>\n",
       "      <th>seller_score</th>\n",
       "      <th>item_price</th>\n",
       "      <th>item_sold</th>\n",
       "      <th>best_offer</th>\n",
       "      <th>title</th>\n",
       "      <th>returns</th>\n",
       "      <th>shipping</th>\n",
       "      <th>condition</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vipoutlet</td>\n",
       "      <td>258955</td>\n",
       "      <td>26900</td>\n",
       "      <td>58</td>\n",
       "      <td>False</td>\n",
       "      <td>Sony CUH-2215A PlayStation 500GB Slim System P...</td>\n",
       "      <td>YES</td>\n",
       "      <td>000</td>\n",
       "      <td>Used</td>\n",
       "      <td>sponsored</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ezprobay99</td>\n",
       "      <td>4009</td>\n",
       "      <td>25499</td>\n",
       "      <td>36</td>\n",
       "      <td>False</td>\n",
       "      <td>Brand New Sony PlayStation 4 Slim 1TB --  Only...</td>\n",
       "      <td>YES</td>\n",
       "      <td>000</td>\n",
       "      <td>New</td>\n",
       "      <td>sponsored</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>normabreede0</td>\n",
       "      <td>15</td>\n",
       "      <td>45000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Sony PlayStation 4 PS4 Slim 1TB Console Marvel...</td>\n",
       "      <td>NO</td>\n",
       "      <td>000</td>\n",
       "      <td>New</td>\n",
       "      <td>sponsored</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>monstertechbids</td>\n",
       "      <td>15342</td>\n",
       "      <td>23999</td>\n",
       "      <td>21</td>\n",
       "      <td>False</td>\n",
       "      <td>Sony Playstation 4 PS4 Slim 1TB Jet Black Cons...</td>\n",
       "      <td>YES</td>\n",
       "      <td>000</td>\n",
       "      <td>Used</td>\n",
       "      <td>sponsored</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alejandrosolanocleats</td>\n",
       "      <td>17</td>\n",
       "      <td>15300</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>Playstation 4 500GB Slim - Black - Great condi...</td>\n",
       "      <td>NO</td>\n",
       "      <td>3500</td>\n",
       "      <td>Used</td>\n",
       "      <td>sponsored</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             seller_name seller_score item_price item_sold best_offer  \\\n",
       "0              vipoutlet       258955      26900        58      False   \n",
       "1             ezprobay99         4009      25499        36      False   \n",
       "2           normabreede0           15      45000         0      False   \n",
       "3        monstertechbids        15342      23999        21      False   \n",
       "4  alejandrosolanocleats           17      15300         0       True   \n",
       "\n",
       "                                               title returns shipping  \\\n",
       "0  Sony CUH-2215A PlayStation 500GB Slim System P...     YES      000   \n",
       "1  Brand New Sony PlayStation 4 Slim 1TB --  Only...     YES      000   \n",
       "2  Sony PlayStation 4 PS4 Slim 1TB Console Marvel...      NO      000   \n",
       "3  Sony Playstation 4 PS4 Slim 1TB Jet Black Cons...     YES      000   \n",
       "4  Playstation 4 500GB Slim - Black - Great condi...      NO     3500   \n",
       "\n",
       "  condition       type  \n",
       "0      Used  sponsored  \n",
       "1       New  sponsored  \n",
       "2       New  sponsored  \n",
       "3      Used  sponsored  \n",
       "4      Used  sponsored  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Concate sponsored_df and non_sponsored_df as a single final dataframe\n",
    "frame = [sponsored_df,non_sponsored_df]\n",
    "final_dataframe = pd.concat(frame)\n",
    "#Reformate the return policy into Yes or No\n",
    "for i in range(len(final_dataframe)):\n",
    "    if final_dataframe.iloc[i,6] == 'Seller does not accept returns':\n",
    "        final_dataframe.iloc[i,6] = 'NO'\n",
    "    else:  final_dataframe.iloc[i,6] = 'YES'\n",
    "final_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect it to the local SQL Server\n",
    "mydb = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"root\"\n",
    ")\n",
    "\n",
    "mycursor = mydb.cursor()\n",
    "\n",
    "#Create Database, table and variables\n",
    "mycursor.execute(\"CREATE DATABASE IF NOT EXISTS eBay\")\n",
    "mycursor.execute(\"USE eBay\")\n",
    "mycursor.execute(\"CREATE TABLE IF NOT EXISTS eBay_items (id INT AUTO_INCREMENT PRIMARY KEY,seller_name VARCHAR(255),seller_score int, item_price int, item_sold int, best_offer VARCHAR(25), title VARCHAR(9999), returns VARCHAR(255), shipping int, Type_Condition VARCHAR(25), Item_Type VARCHAR(25))\")\n",
    "\n",
    "\n",
    "\n",
    "#Loop the dataframe and add value into each of the variable\n",
    "for i in range(len(final_dataframe)):\n",
    "    sql = 'INSERT INTO eBay_items (seller_name, seller_score, item_price, item_sold, best_offer, title, returns, shipping,Type_Condition,Item_Type) VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)'\n",
    "    val = final_dataframe.iloc[i,0],final_dataframe.iloc[i,1],final_dataframe.iloc[i,2],final_dataframe.iloc[i,3],final_dataframe.iloc[i,4],final_dataframe.iloc[i,5],final_dataframe.iloc[i,6],final_dataframe.iloc[i,7],final_dataframe.iloc[i,8],final_dataframe.iloc[i,9]\n",
    "    mycursor.execute(sql,val)\n",
    "\n",
    "mydb.commit()  \n",
    "    \n",
    "    \n",
    "mydb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "facts for seller_score: \n",
      "Item_Type  -  Condition  -  Mean  -        Max  -   Min\n",
      "('sponsored', 'Used', Decimal('21560.3500'), 258955, 0)\n",
      "('sponsored', 'New', Decimal('15844.0222'), 568396, 0)\n",
      "('sponsored', 'Seller refurbished', Decimal('15099.2500'), 41457, 0)\n",
      "('sponsored', 'Open box', Decimal('11246.5000'), 64483, 5)\n",
      "('sponsored', 'Manufacturer refurbished', Decimal('56.0000'), 56, 56)\n",
      "('non-sponsored', 'Seller refurbished', Decimal('160004.3235'), 2265933, 0)\n",
      "('non-sponsored', 'Used', Decimal('41001.5717'), 258958, 0)\n",
      "('non-sponsored', 'New', Decimal('14165.8805'), 916886, 0)\n",
      "('non-sponsored', 'Open box', Decimal('14498.5893'), 568398, 0)\n",
      "('non-sponsored', 'Manufacturer refurbished', Decimal('283314.3750'), 2265917, 0)\n"
     ]
    }
   ],
   "source": [
    "#Part F\n",
    "mydb = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"root\",\n",
    "  database = \"ebay\"\n",
    ")\n",
    "#Get the stats of seller_score\n",
    "mycursor = mydb.cursor()\n",
    "mycursor.execute(\"SELECT Item_Type, Type_Condition, avg(seller_score),max(seller_score), min(seller_score) FROM eBay_items GROUP BY Item_Type,Type_Condition\")\n",
    "data = mycursor.fetchall()\n",
    "print(\"facts for seller_score: \")\n",
    "print('Item_Type  -  Condition  -  Mean  -        Max  -   Min')\n",
    "for i in data:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "facts for item_price: \n",
      "Item_Type  -  Condition  -  Mean  -        Max  -   Min\n",
      "('sponsored', 'Used', Decimal('27180.1000'), 55351, 14599)\n",
      "('sponsored', 'New', Decimal('32275.7333'), 57999, 22100)\n",
      "('sponsored', 'Seller refurbished', Decimal('22999.5000'), 25300, 19999)\n",
      "('sponsored', 'Open box', Decimal('24215.0000'), 33500, 16995)\n",
      "('sponsored', 'Manufacturer refurbished', Decimal('33900.0000'), 33900, 33900)\n",
      "('non-sponsored', 'Seller refurbished', Decimal('21571.4412'), 36995, 7100)\n",
      "('non-sponsored', 'Used', Decimal('20615.6667'), 50000, 99)\n",
      "('non-sponsored', 'New', Decimal('31152.1352'), 157500, 4600)\n",
      "('non-sponsored', 'Open box', Decimal('24741.9821'), 52995, 12500)\n",
      "('non-sponsored', 'Manufacturer refurbished', Decimal('18506.0000'), 25000, 10250)\n"
     ]
    }
   ],
   "source": [
    "#Get the stats of item_price\n",
    "mycursor = mydb.cursor()\n",
    "mycursor.execute(\"SELECT Item_Type, Type_Condition, avg(item_price),max(item_price), min(item_price) FROM eBay_items GROUP BY Item_Type,Type_Condition\")\n",
    "data = mycursor.fetchall()\n",
    "print(\"facts for item_price: \")\n",
    "print('Item_Type  -  Condition  -  Mean  -        Max  -   Min')\n",
    "for i in data:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "facts for item_sold: \n",
      "Item_Type  -  Condition  -  Mean  -        Max  -   Min\n",
      "('sponsored', 'Used', Decimal('1.5000'), 58, 0)\n",
      "('sponsored', 'New', Decimal('7.5778'), 99, 0)\n",
      "('sponsored', 'Seller refurbished', Decimal('1.2500'), 4, 0)\n",
      "('sponsored', 'Open box', Decimal('0.8333'), 5, 0)\n",
      "('sponsored', 'Manufacturer refurbished', Decimal('0.0000'), 0, 0)\n",
      "('non-sponsored', 'Seller refurbished', Decimal('2.7059'), 43, 0)\n",
      "('non-sponsored', 'Used', Decimal('0.2597'), 58, 0)\n",
      "('non-sponsored', 'New', Decimal('9.7516'), 872, 0)\n",
      "('non-sponsored', 'Open box', Decimal('2.2857'), 119, 0)\n",
      "('non-sponsored', 'Manufacturer refurbished', Decimal('1.0000'), 5, 0)\n"
     ]
    }
   ],
   "source": [
    "#Get the stats of item_sold\n",
    "mycursor = mydb.cursor()\n",
    "mycursor.execute(\"SELECT Item_Type, Type_Condition, avg(item_sold),max(item_sold), min(item_sold) FROM eBay_items GROUP BY Item_Type,Type_Condition\")\n",
    "data = mycursor.fetchall()\n",
    "print(\"facts for item_sold: \")\n",
    "print('Item_Type  -  Condition  -  Mean  -        Max  -   Min')\n",
    "for i in data:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "facts for best_offer is FALSE: \n",
      "Item_Type  -  Condition  -  Count\n",
      "('sponsored', 'Used', 28)\n",
      "('sponsored', 'New', 34)\n",
      "('sponsored', 'Seller refurbished', 3)\n",
      "('sponsored', 'Open box', 1)\n",
      "('non-sponsored', 'Seller refurbished', 20)\n",
      "('non-sponsored', 'Used', 304)\n",
      "('non-sponsored', 'New', 231)\n",
      "('non-sponsored', 'Open box', 26)\n",
      "('non-sponsored', 'Manufacturer refurbished', 3)\n"
     ]
    }
   ],
   "source": [
    "#Get the stats of best_offer\n",
    "mycursor = mydb.cursor()\n",
    "mycursor.execute(\"SELECT Item_Type, Type_Condition, count(best_offer) FROM eBay_items WHERE best_offer = 'FALSE' GROUP BY Item_Type,Type_Condition\")\n",
    "data = mycursor.fetchall()\n",
    "print(\"facts for best_offer is FALSE: \")\n",
    "print('Item_Type  -  Condition  -  Count')\n",
    "for i in data:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "facts for returns is YES: \n",
      "Item_Type  -  Condition  -  Count\n",
      "('sponsored', 'Used', 33)\n",
      "('sponsored', 'New', 33)\n",
      "('sponsored', 'Seller refurbished', 3)\n",
      "('sponsored', 'Open box', 3)\n",
      "('non-sponsored', 'Seller refurbished', 17)\n",
      "('non-sponsored', 'Used', 229)\n",
      "('non-sponsored', 'New', 163)\n",
      "('non-sponsored', 'Manufacturer refurbished', 3)\n",
      "('non-sponsored', 'Open box', 14)\n"
     ]
    }
   ],
   "source": [
    "#Get the stats of returns\n",
    "mycursor = mydb.cursor()\n",
    "mycursor.execute(\"SELECT Item_Type, Type_Condition, count(returns) FROM eBay_items WHERE returns = 'YES' GROUP BY Item_Type,Type_Condition\")\n",
    "data = mycursor.fetchall()\n",
    "print(\"facts for returns is YES: \")\n",
    "print('Item_Type  -  Condition  -  Count')\n",
    "for i in data:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Close the connection with SQL Server\n",
    "mydb.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#G\n",
    "By looking at the stats fact that generated in part F, there are two ways to classify sponsored and non-sponsored types. First way is looking at the seller_score. The other difference is item_price. In seller_score section, under each condition, the seller who sells non-sponsored type would generally has more scores than the the one who sells sponsored type. On the other hand, the condition surprsingly changes in item_price. Sponsored type generally has higher price than the non-sponsored type, with roughly 60-100$ excess."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
